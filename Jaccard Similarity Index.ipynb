{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Similarity index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we discuss the Jaccard similarity index and how to calculate it.<br>\n",
    "The Jaccard simiarity index which is an index of similarity can best be explained using set theory.<br>\n",
    "The formula  is a given below:- \n",
    "\n",
    "$J(A,B)= \\frac {|A \\bigcap B|}{|A \\bigcup B|} $\n",
    "\n",
    "Here we see if the elements in A & B are identical the Jaccard simiarity index = 1.<br>\n",
    "If there are no common elements it is 0.<br>\n",
    "For all other possibilites it varies between 0 & 1.<br>\n",
    "\n",
    "Lets explore the python code for the same.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the input file and remove all the stop words.<br>\n",
    "A RegexpTokenizer is used which is used to remove any punctuations.<br>\n",
    "This is done for both the files to be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cats', 'similar', 'anatomy', 'felids', 'strong', 'flexible', 'body', 'quick', 'reflexes', 'sharp', 'retractable', 'claws', 'teeth', 'adapted', 'killing', 'small', 'prey', 'Cat', 'senses', 'fit', 'crepuscular', 'predatory', 'ecological', 'niche', 'Cats', 'hear', 'sounds', 'faint', 'high', 'frequency', 'human', 'ears', 'made', 'mice', 'small', 'animals', 'They', 'see', 'near', 'darkness', 'Like', 'mammals', 'cats', 'poorer', 'color', 'vision', 'better', 'sense', 'smell', 'humans', 'Cats', 'despite', 'solitary', 'hunters', 'social', 'species', 'cat', 'communication', 'includes', 'use', 'variety', 'vocalizations', 'mewing', 'purring', 'trilling', 'hissing', 'growling', 'grunting', 'well', 'cat', 'pheromones', 'types', 'cat', 'specific', 'body', 'language', '7', 'Cats', 'high', 'breeding', 'rate', '8', 'Under', 'controlled', 'breeding', 'bred', 'shown', 'registered', 'pedigree', 'pets', 'hobby', 'known', 'cat', 'fancy', 'Failure', 'control', 'breeding', 'pet', 'cats', 'neutering', 'well', 'abandonment', 'former', 'household', 'pets', 'resulted', 'large', 'numbers', 'feral', 'cats', 'worldwide', 'requiring', 'population', 'control', '9', 'In', 'certain', 'areas', 'outside', 'cats', 'native', 'range', 'contributed', 'along', 'habitat', 'destruction', 'factors', 'extinction', 'many', 'bird', 'species', 'Cats', 'known', 'extirpate', 'bird', 'species', 'within', 'specific', 'regions', 'may', 'contributed', 'extinction', 'isolated', 'island', 'populations', '10', 'Cats', 'thought', 'primarily', 'responsible', 'extinction', '33', 'species', 'birds', 'since', '1600s', 'better', 'source', 'needed', 'presence', 'feral', 'free', 'ranging', 'cats', 'makes', 'otherwise', 'suitable', 'locations', 'unsuitable', 'attempted', 'species', 'reintroduction', '11', 'Because', 'cats', 'venerated', 'ancient', 'Egypt', 'commonly', 'believed', 'domesticated', '12', 'may', 'instances', 'domestication', 'early', 'Neolithic', 'around', '9', '500', 'years', 'ago', '7500', 'BC', '13', 'A', 'genetic', 'study', '2007', '14', 'concluded', 'domestic', 'cats', 'descended', 'Near', 'Eastern', 'wildcats', 'diverged', 'around', '8000', 'BC', 'Middle', 'East', '12', '15', 'A', '2016', 'study', 'found', 'leopard', 'cats', 'undergoing', 'domestication', 'independently', 'China', 'around', '5500', 'BC', 'though', 'line', 'partially', 'domesticated', 'cats', 'leaves', 'trace', 'domesticated', 'populations', 'today', '16', '17', 'A', '2017', 'study', 'confirmed', 'domestic', 'cats', 'descendants', 'first', 'domesticated', 'farmers', 'Near', 'East', 'around', '9', '000', 'years', 'ago', '18', '19', 'As', '2007', 'study', 'cats', 'second', 'popular', 'pet', 'U', 'S', 'number', 'pets', 'owned', 'behind', 'freshwater', 'fish', '20', 'In', '2010', 'study', 'ranked', 'third', 'popular', 'pet', 'UK', 'fish', 'dogs', 'around', '8', 'million', 'owned', '21']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "f=open('D:/Sample files/Sample 1.txt','rU')\n",
    "raw=f.read()\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "tokens=tokenizer.tokenize(raw)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentence_1= [w for w in tokens if not w in stop_words]\n",
    "print(filtered_sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'domestic', 'dog', 'Canis', 'lupus', 'familiaris', 'considered', 'subspecies', 'gray', 'wolf', 'Canis', 'familiaris', 'considered', 'distinct', 'species', '4', 'member', 'genus', 'Canis', 'canines', 'forms', 'part', 'wolf', 'like', 'canids', '5', 'widely', 'abundant', 'terrestrial', 'carnivore', '6', '7', '8', '9', '10', 'The', 'dog', 'extant', 'gray', 'wolf', 'sister', 'taxa', '11', '12', '13', 'modern', 'wolves', 'closely', 'related', 'wolves', 'first', 'domesticated', '12', '13', 'implies', 'direct', 'ancestor', 'dog', 'extinct', '14', 'The', 'dog', 'first', 'species', 'domesticated', '13', '15', 'selectively', 'bred', 'millennia', 'various', 'behaviors', 'sensory', 'capabilities', 'physical', 'attributes', '16', 'Their', 'long', 'association', 'humans', 'led', 'dogs', 'uniquely', 'attuned', 'human', 'behavior', '17', 'able', 'thrive', 'starch', 'rich', 'diet', 'would', 'inadequate', 'canid', 'species', '18', 'New', 'research', 'seems', 'show', 'dogs', 'mutations', 'equivalent', 'genetic', 'regions', 'humans', 'changes', 'known', 'trigger', 'high', 'sociability', 'somewhat', 'reduced', 'intelligence', '19', '20', 'Dogs', 'vary', 'widely', 'shape', 'size', 'colors', '21', 'Dogs', 'perform', 'many', 'roles', 'people', 'hunting', 'herding', 'pulling', 'loads', 'protection', 'assisting', 'police', 'military', 'companionship', 'recently', 'aiding', 'handicapped', 'individuals', 'therapeutic', 'roles', 'This', 'influence', 'human', 'society', 'given', 'sobriquet', 'man', 'best', 'friend']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "f=open('D:/Sample files/Sample 2.txt','rU')\n",
    "raw=f.read()\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "tokens=tokenizer.tokenize(raw)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentence_2= [w for w in tokens if not w in stop_words]\n",
    "print(filtered_sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the Stemmer.<br>\n",
    "Stemming converts common words to a single one.<br>\n",
    "Example run , runnning , ran are converted to run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence_1_stem = []\n",
    "for w in filtered_sentence_1:\n",
    "    filtered_sentence_1_stem.append(ps.stem(w)) \n",
    "    \n",
    "filtered_sentence_2_stem = []\n",
    "for w in filtered_sentence_2:\n",
    "    filtered_sentence_2_stem.append(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we calcualte and print the Jaccard Similarity Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect=len(set(filtered_sentence_2_stem).intersection(filtered_sentence_1_stem))\n",
    "union_all=len(set(filtered_sentence_2_stem).union(filtered_sentence_1_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "295\n",
      "Jaccard Similarity Index is:- 0.09830508474576272\n"
     ]
    }
   ],
   "source": [
    "print(intersect)\n",
    "print(union_all)\n",
    "print('Jaccard Similarity Index is:- '+str(intersect/union_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
