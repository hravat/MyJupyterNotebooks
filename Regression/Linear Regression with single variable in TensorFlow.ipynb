{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Singe variable with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to provide a basic understanding of Linear Regression with a single variable.<br>\n",
    "Once the understaning is clear we will implement a linear regression model in TensolrFlow \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what exactly is Linear Regression ?<br>\n",
    "Lets have a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a very simple mathametical game you might have where you are given a two sequence of numbers where you have to guess the next number.\n",
    "To make things simpler to lets take the below seqeunce.<br>\n",
    "\n",
    "<b>Sequence 1 (x):-</b>  1,2,3,4,5<br>\n",
    "<b>Sequence 2 (y):-</b>  3,6,9,12,15<br>\n",
    "\n",
    "Now you are given a new number in x say 6 and are asked to guess wht the value of y would be.<br>\n",
    "You can easily guess it as  18. However is there any method for properly arriving at this value??<br>\n",
    "Here is where Linear Regerssion comes in handy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the above topic we need first understand the three words that make up the topic<br>\n",
    "<b> 1.) Regression </b> It is a statistical method to determine the relationship between dependent variable and one or many independent vairalbes. In our above example x is the independet vaariable while y is the dependent variable i.e it depends on x.<br> \n",
    "<b> 2.) Linear </b> The highest degree of any independent variable in is 1.<br>\n",
    "<b> 3.) Single variable </b> The is only one independent variable.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having understood these terms lets the the relationship between x & y<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "y & = \\theta*x \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to loss a cost function so that the predicted values and the actual values of Y are as less as possible<br>\n",
    "Lets define it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "J(\\theta) & = \\frac{1}{2m}\\sum_{i=1}^m  (\\theta x^{(i)}-y^{(i)})^2 \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that we need to minimize where i is number of exapmles which is 5 in our case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will not be explaining Gradient descent but will present the equations required for Gradient descent<br>\n",
    "Our goal is to find out the value of \\begin{align}\\theta \\end{align}\n",
    "\n",
    "such that\n",
    "\n",
    "\\begin{align}\n",
    "J(\\theta)  \n",
    "\\end{align}\n",
    "\n",
    "is mimnimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic rule for graident descent is as given below:-\n",
    "\n",
    "\\begin{align}\n",
    "\\theta & :=  \\theta - \\alpha \\frac{d}{d\\theta} J(\\theta) \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{d}{d\\theta} J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m  (\\theta  (x^{(i)})^2-y^{(i)} x^{(i)}) \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an understanding lets move to tensorflow.Tensor Flow is an open source software Library developed by google.<br>\n",
    "Not that in tensorflow we do not need to implement the Gradient desent equation as it is taken care of by tensorflow itself<br>\n",
    "Lets start with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the essential stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here x and y are place holders they represent the inputs to our model and correspond to x & y of our above example<br>\n",
    "W is a variable and while change. It correspneds to theta in our above exalpmlple\n",
    "On the end we define the relationship between x & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None,1],name='x')\n",
    "y = tf.placeholder(tf.float32, [None,1],name='y')\n",
    "W = tf.Variable([5.0], tf.float32)\n",
    "linear_model=tf.multiply(W,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_arr=np.array([1,2,3,4,5])\n",
    "y_arr=np.array([4,8,12,16,20])\n",
    "x_arr=x_arr.reshape(5,1)\n",
    "y_arr=y_arr.reshape(5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the cost function and the Gradint Descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.sqrt(tf.square(tf.subtract(linear_model,y))))/5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_plot=[]\n",
    "for i in range(500):\n",
    "    _,loss_val,W_val=sess.run([train , loss , W], feed_dict = {x: x_arr, y: y_arr})\n",
    "    weight_plot.append([i,loss_val,W_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pred_temp=np.array([6,7,8,9,10])\n",
    "x_pred=x_pred_temp.reshape(5,1)\n",
    "y_pred = sess.run(linear_model, feed_dict={x:x_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_arr=np.array([1,2,3,4,5])\n",
    "y_arr=np.array([4,8,12,16,20])\n",
    "result_final=float(weight_plot[len(weight_plot)-1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "func = np.arange(1.0, 11.1,0.1)\n",
    "x_arr=np.array([1,2,3,4,5])\n",
    "y_arr=np.array([4,8,12,16,20])\n",
    "pred_x = sns.regplot(x_arr, y_arr,fit_reg=False,color=\"red\");\n",
    "ax = sns.regplot(x_pred_temp, y_pred,fit_reg=False,color=\"yellow\");\n",
    "plt.plot (func, func*result_final ,color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a perfect linear relationship between the dependent and independent variables<br>\n",
    "The green line represents the function predicted by our model while the red points represent the input to the model.\n",
    "The yelloe points reprent the output predicted by the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also plot the cost,W over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iteration=[]\n",
    "losses=[]\n",
    "weights=[]\n",
    "for i in range(len(weight_plot)):\n",
    "    iteration.append(weight_plot[i][0])\n",
    "    losses.append(weight_plot[i][1])\n",
    "    weights.append(weight_plot[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\", font_scale=1.5)\n",
    "plt.plot (iteration, weights ,color=\"green\")\n",
    "plt.plot (iteration, losses ,color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we clearly see that cost decreases to 0 while W gets stabilized at 4.<br>\n",
    "The value thus matches with our intutuion i.e. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
